{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Wrangling Project of Pune_India.osm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## by Sebastian P Joseph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pune is a sprawling city in the western Indian state of Maharashtra. It was once the base of the Peshwas (prime ministers) of the Maratha Empire, which lasted from 1674 to 1818. It's known for the grand Aga Khan Palace, built in 1892 and now a memorial to Mahatma Gandhi, whose ashes are preserved in the garden. The 8th-century Pataleshwar Cave Temple is dedicated to the Hindu god Shiva. \n",
    "\n",
    "Moreover its my hometown , and its one of the most upcoming city in INDIA. So i felt i could take up that city for my project and explore a bit more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When I explored the data a bit i found that most of the errors are found in the street names area and the postal codes area."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Street names\n",
    "\n",
    "2. Postal codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Street names "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first part of the code i have decided to display all the street names. I have mentioned some expected words to come in the end which might come in the pune dataset. They are as follows.\n",
    "\n",
    "expected = [\"Street\", \"Avenue\",\"Apartment\",\"Ridge\",\"Annexe\",\"City\",\"Society\",\"Area\",\"Bunk\",\"Centre\",\"Station\",\"Circle\",\n",
    "            \"Nagar\",\"Stage\",\"Stop\",\"Lake\",\"World\",\"Plaza\",\"Phase\",\"Bazaar\",\"Park\",\"Colony\",\"Commons\",\"Mall\",\"Trail\",\n",
    "            \"Path\",\"Road\",\"Gate\",\"Town\",\"Drive\",\"Block\"]\n",
    "            \n",
    "I have printed all the street types as you can see in the notebook file.\n",
    "\n",
    "In the next part I have tried to clean some street types which i could find. They are mentioned below.\n",
    "\n",
    "mapping={\" , Pune\":\"\",\n",
    "         \"cross\":\"Cross\",\n",
    "        \"Rd.\":\"Road\",\n",
    "        \"Rd\":\"Road\",\n",
    "        \"road\":\"Road\",\n",
    "        \"raod\":\"Road\",\n",
    "        \"apartment\":\"Apartment\",\n",
    "        \"no.\":\"\",\n",
    "        \"udyog\":\"Udyog\",\n",
    "        \"pedestrian\":\"Pedestrian\"\n",
    "        }\n",
    "        \n",
    "I have tried to map them to the original words and printed the output using the variable update_street."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Postal Codes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the second part i have decided to display the postal codes. everything ,if there is error in it or not.\n",
    "\n",
    "Then exploring it a bit,I found that some postal codes have spaces in between. Eg: 413 321\n",
    "\n",
    "Then some postal codes are in the form of string.\n",
    "\n",
    "Then some postal codes are out of the city limits. The city postal codes range is from 411001 to 411053\n",
    "\n",
    "Then I started cleaning the postal codes and printed all the cleaned postal codes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part of the code i have created the CSV files required to create the database to pass the queries.\n",
    "\n",
    "NODES_PATH = \"nodes.csv\"\n",
    "\n",
    "NODE_TAGS_PATH = \"nodes_tags.csv\"\n",
    "\n",
    "WAYS_PATH = \"ways.csv\"\n",
    "\n",
    "WAY_NODES_PATH = \"ways_nodes.csv\"\n",
    "\n",
    "WAY_TAGS_PATH = \"ways_tags.csv\"\n",
    "\n",
    "The details of the files are as follows:\n",
    "\n",
    "nodes.csv (114MB)\n",
    "\n",
    "nodes_tags.csv (528KB)\n",
    "\n",
    "ways.csv (15.9MB)\n",
    "\n",
    "ways_nodes.csv (40.7MB)\n",
    "\n",
    "ways_tags.csv (9.27MB)\n",
    "\n",
    "The next step is to create database. I have created a database named seb_pune.db using the database.py python file attached."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Queries and answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 1. Number of nodes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         0\n",
      "0  1418393\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "data=sqlite3.connect(\"seb_pune.db\")\n",
    "c=data.cursor()\n",
    "QUERY='''SELECT count(*)as num from nodes;'''\n",
    "c.execute(QUERY)\n",
    "rows=c.fetchall()\n",
    "import pandas as pd    \n",
    "dataframe=pd.DataFrame(rows)\n",
    "print dataframe\n",
    "data.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Number of ways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        0\n",
      "0  270313\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "data=sqlite3.connect(\"seb_pune.db\")\n",
    "c=data.cursor()\n",
    "QUERY='''SELECT count(*)as num from ways;'''\n",
    "c.execute(QUERY)\n",
    "rows=c.fetchall()\n",
    "import pandas as pd    \n",
    "dataframe=pd.DataFrame(rows)\n",
    "print dataframe\n",
    "data.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Number of unique users "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           0\n",
      "0                   PlaneMad\n",
      "1                      norky\n",
      "2                  singleton\n",
      "3                    Heinz_V\n",
      "4                        JND\n",
      "5            Rahul Maindargi\n",
      "6                  katpatuka\n",
      "7                  shalinins\n",
      "8                 mapusdotin\n",
      "9              nirvanareborn\n",
      "10            Pradnya shende\n",
      "11                   shiva05\n",
      "12                adivik2000\n",
      "13                    Mettal\n",
      "14                  AdyShake\n",
      "15                AbhishekAJ\n",
      "16             Manas Sambhus\n",
      "17                 maheshrkm\n",
      "18                Navaneetha\n",
      "19                  mahesham\n",
      "20                     vraju\n",
      "21                   aveekbh\n",
      "22                   cdavila\n",
      "23                 parambyte\n",
      "24                    uday01\n",
      "25             Indrayudh Roy\n",
      "26                   fulcrum\n",
      "27                    Tinkle\n",
      "28   Praveen Arimbrathodiyil\n",
      "29                  Oberaffe\n",
      "..                       ...\n",
      "661                  SUVIRON\n",
      "662        prashant bhaskara\n",
      "663                 AmolBhat\n",
      "664                    Adi28\n",
      "665           Subodh Bangale\n",
      "666                   ankeyc\n",
      "667             Rohan Thorat\n",
      "668      Pioneer Impressions\n",
      "669                      X I\n",
      "670             Mahesh Awhad\n",
      "671                ROSHINI25\n",
      "672           Shantanu Joshi\n",
      "673                Ajay Nair\n",
      "674                    chats\n",
      "675              Ashish Raut\n",
      "676           Pannkaj Osswal\n",
      "677               Gurumantra\n",
      "678           Hitesh Barhate\n",
      "679           Ravindra Patil\n",
      "680             prafful lele\n",
      "681   Dnyaneshwar Rajkuntwar\n",
      "682           Sandeep Parkhi\n",
      "683                   LSSuls\n",
      "684           Anil Pisharody\n",
      "685         Sourabh Nanaware\n",
      "686               Nutan Lele\n",
      "687      Aniket Pandharabale\n",
      "688            Manish Ostwal\n",
      "689           Christoph Lotz\n",
      "690            rahul punjabi\n",
      "\n",
      "[691 rows x 1 columns]\n",
      "691 Unique users\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "data=sqlite3.connect(\"seb_pune.db\")\n",
    "c=data.cursor()\n",
    "QUERY='''SELECT DISTINCT(user) from (select user from nodes UNION ALL select user from ways);'''\n",
    "c.execute(QUERY)\n",
    "rows=c.fetchall()\n",
    "import pandas as pd    \n",
    "dataframe=pd.DataFrame(rows)\n",
    "print dataframe\n",
    "print len(dataframe),\"Unique users\"\n",
    "data.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Top 10 contributing users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               0      1\n",
      "0      singleton  96636\n",
      "1    harishvarma  60143\n",
      "2  jasvinderkaur  57694\n",
      "3        sramesh  57627\n",
      "4       praveeng  56788\n",
      "5        shiva05  51899\n",
      "6    anushapyata  49530\n",
      "7   kranthikumar  47440\n",
      "8        harishk  43180\n",
      "9       saikumar  40332\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "data=sqlite3.connect(\"seb_pune.db\")\n",
    "c=data.cursor()\n",
    "QUERY='''SELECT user,count(user)  from (select user from nodes UNION ALL select user from ways)\n",
    "group by user \n",
    "order by  count(user) desc \n",
    "limit 10;'''\n",
    "c.execute(QUERY) \n",
    "rows=c.fetchall()\n",
    "import pandas as pd    \n",
    "dataframe=pd.DataFrame(rows)\n",
    "print dataframe\n",
    "data.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Biggest religion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0    1\n",
      "0  hindu  227\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "data=sqlite3.connect(\"seb_pune.db\")\n",
    "c=data.cursor()\n",
    "QUERY='''SELECT value,count(*)as num from (select value,key from nodes_tags  UNION ALL select value,key from ways_tags)\n",
    "where key='religion'\n",
    "group by value\n",
    "order by num desc\n",
    "limit 1;'''\n",
    "c.execute(QUERY)\n",
    "rows=c.fetchall()\n",
    "import pandas as pd    \n",
    "dataframe=pd.DataFrame(rows)\n",
    "print dataframe\n",
    "data.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Top 10 appearing amenities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            0    1\n",
      "0  restaurant  153\n",
      "1        cafe   55\n",
      "2    hospital   48\n",
      "3   fast_food   46\n",
      "4        bank   45\n",
      "5      school   39\n",
      "6     toilets   34\n",
      "7         atm   30\n",
      "8        fuel   25\n",
      "9    pharmacy   24\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "data=sqlite3.connect(\"seb_pune.db\")\n",
    "c=data.cursor()\n",
    "QUERY='''SELECT value,count(*)as num from (select value,key from nodes_tags  UNION ALL select value,key from ways_tags)\n",
    "where key='amenity'\n",
    "group by value\n",
    "order by num desc\n",
    "limit 10;'''\n",
    "c.execute(QUERY)\n",
    "rows=c.fetchall()\n",
    "import pandas as pd    \n",
    "dataframe=pd.DataFrame(rows)\n",
    "print dataframe\n",
    "data.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explanations and Suggestions: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above queries we know the following:\n",
    "    \n",
    "1 Total number of nodes are 1418393\n",
    "\n",
    "2 Total number of ways are 270313\n",
    "\n",
    "3 There are 691 unique users\n",
    "\n",
    "4 Singleton contributes the most \n",
    "\n",
    "5 Biggest religion in Pune is HINDU\n",
    "\n",
    "6 Restaurant tops the amenities list in PUNE\n",
    " \n",
    " Thinking about these values, I’m reminded of “gamification” as a motivating force for contribution. In the context of the OpenStreetMap, if user data were more prominently displayed, perhaps others would take an initiative in submitting more edits to the map. And, if everyone sees that only a handful of power users are creating more than 90% a of given map, that might spur the creation of more efficient bots, especially if certain gamification elements were present, such as rewards, badges, or a leaderboard. But it is easy to give the suggestions but, there are also equal dis advantages to it.The authenticity of the map might be under risk. I guess that might be a  problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above mentioned explanation I think I have possibly done my part to clean the dataset and I have answered the queries needed. After this review of the data it’s obvious that the Pune area is incomplete, though I believe it has been well cleaned for the purposes of this exercise. It interests me to notice a fair amount of GPS data makes it into OpenStreetMap.org on account of users’ efforts, whether by scripting a map editing bot or otherwise. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
